{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lib.p3_ProcessLogger import ProcessLogger\n",
    "cell_log = ProcessLogger() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Project: Adopt a Drain\n",
    " * Author: James Wilfong, wilfongjt@gmail.com\n",
    " \n",
    "## Basics\n",
    "* data processed in a local clone of source-data \n",
    "* intermediate files are put into source-data repo\n",
    "* the final data.world data set name is the same as the raw-data file name\n",
    "* the source-data repo folders /raw-data, /clean-data, /notebook are updated during the process\n",
    "\n",
    "## Raw-data Process\n",
    "* input: raw-data/ \n",
    "* use python via jupyter notebook to manipulate data into usable file\n",
    "* update results to github\n",
    "* output: clean-data/\n",
    "\n",
    "## GIT Process\n",
    "* input: clean-data/\n",
    "* process: add, commit, push files from raw-data/, clean-data/, notebook/ folders\n",
    "* output: GitHub source-data repo\n",
    "\n",
    "## Data.World Process\n",
    "* input: GitHub source-data/clean-data/\n",
    "* process: transfer github clean-data/ to data.world\n",
    "* output: data.world\n",
    "\n",
    "## Table of Contents\n",
    "* [Introduction](#intro)\n",
    "\n",
    "* [Data Wrangling](#wrangling_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## Introduction\n",
    "* why adopt a drain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prerequisites'></a>\n",
    "## Prerequisites\n",
    "* create [Github](#github) repository to hold raw data\n",
    "* create [Data World](#data-world) account\n",
    "* [Notebook Config](#notebook-config)\n",
    "* [Environment Variable Setup](#env-setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data-world'></a>\n",
    "## Dataworld\n",
    "* Set up an account\n",
    "* DW_AUTH_TOKEN value comes from your [data.world](https://data.world/) account-settings-advanced-Admin.\n",
    "* Application data is stored in data.world\n",
    "* A Data.world dataset is mostly read-only\n",
    "* A Data.world is updated via file replacement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='github'></a>\n",
    "## Github\n",
    "\n",
    "* raw-data is loaded from the remote source-data repo on Github\n",
    "* raw-data is stored in the /raw-data folder of the source-data repo\n",
    "* raw-data is pushed to the remote source-data repo before running this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='env-setup'></a>\n",
    "## Environment Variable Setup\n",
    "* Create a file .env and put in the /notebook folder\n",
    "* .env does not get included in the github repository. Exclude .env from github in the .gitignore file\n",
    "* Add environment variables to .env file\n",
    "    * DW_USER=your-data-world-user-name\n",
    "    * GH_URL=https://raw.githubusercontent.com/Wilfongjt/source-data/master/raw-data/\n",
    "    * DW_DB_URL=https://api.data.world/v0/datasets/wilfongjt/\n",
    "    * DW_DB_RW_TOKEN=dataworld-token\n",
    "    * DW_ADM_TOKEN=dataworld-adm-token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Load Packages\n",
       "* Load environment variables\n",
       "* Import third party packages\n",
       "* Import custom packages"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_log.clear()\n",
    "cell_log.collect('## Load Packages')\n",
    "# import dotenv\n",
    "cell_log.collect('* Load environment variables')\n",
    "from settings import *\n",
    "cell_log.collect('* Import third party packages')\n",
    "# from exceptions import ApiException\n",
    "from datadotworld.client import _swagger\n",
    "import datadotworld as dw\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import csv # read and write csv files\n",
    "from IPython.display import display, HTML\n",
    "from IPython.display import Markdown\n",
    "from pprint import pprint\n",
    "import time\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# convenience functions -- cleaning\n",
    "cell_log.collect('* Import custom packages')\n",
    "from lib.p3_CellCounts import CellCounts\n",
    "import lib.p3_clean as clean\n",
    "from lib.p3_configuration import get_configuration\n",
    "import lib.p3_explore as explore\n",
    "import lib.p3_gather as gather # gathering functions\n",
    "import lib.p3_helper_functions as helper\n",
    "import lib.p3_map as maps\n",
    "\n",
    "Markdown('''{}'''.format(cell_log.getMarkdown()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /Users/jameswilfong/anaconda/lib/python3.6/site-packages\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: datadotworld[pandas] in /Users/jameswilfong/anaconda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: jsontableschema<1.0a,>=0.10.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from datadotworld[pandas])\n",
      "Requirement already satisfied: requests<3.0a,>=2.0.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from datadotworld[pandas])\n",
      "Requirement already satisfied: datapackage<1.0a,>=0.8.8 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from datadotworld[pandas])\n",
      "Requirement already satisfied: six<2.0a,>=1.5.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from datadotworld[pandas])\n",
      "Requirement already satisfied: tabulator<=1.4.1 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from datadotworld[pandas])\n",
      "Requirement already satisfied: flake8<3.4.1a,>=2.6.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from datadotworld[pandas])\n",
      "Requirement already satisfied: certifi>=2017.04.17 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from datadotworld[pandas])\n",
      "Requirement already satisfied: configparser<4.0a,>=3.5.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from datadotworld[pandas])\n",
      "Requirement already satisfied: urllib3<2.0a,>=1.15 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from datadotworld[pandas])\n",
      "Requirement already satisfied: click<7.0a,>=6.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from datadotworld[pandas])\n",
      "Requirement already satisfied: python-dateutil<3.0a,>=2.6.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from datadotworld[pandas])\n",
      "Requirement already satisfied: pandas<1.0a; extra == \"pandas\" in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from datadotworld[pandas])\n",
      "Requirement already satisfied: rfc3986<1.0,>=0.4 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from jsontableschema<1.0a,>=0.10.0->datadotworld[pandas])\n",
      "Requirement already satisfied: isodate<1.0,>=0.5.4 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from jsontableschema<1.0a,>=0.10.0->datadotworld[pandas])\n",
      "Requirement already satisfied: future<1.0,>=0.15 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from jsontableschema<1.0a,>=0.10.0->datadotworld[pandas])\n",
      "Requirement already satisfied: jsonschema<3.0,>=2.5 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from jsontableschema<1.0a,>=0.10.0->datadotworld[pandas])\n",
      "Requirement already satisfied: unicodecsv<1.0,>=0.14 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from jsontableschema<1.0a,>=0.10.0->datadotworld[pandas])\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from requests<3.0a,>=2.0.0->datadotworld[pandas])\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from requests<3.0a,>=2.0.0->datadotworld[pandas])\n",
      "Requirement already satisfied: jsonlines<2.0,>=1.1 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from tabulator<=1.4.1->datadotworld[pandas])\n",
      "Requirement already satisfied: cchardet<2.0,>=1.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from tabulator<=1.4.1->datadotworld[pandas])\n",
      "Requirement already satisfied: ijson<3.0,>=2.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from tabulator<=1.4.1->datadotworld[pandas])\n",
      "Requirement already satisfied: xlrd<2.0,>=1.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from tabulator<=1.4.1->datadotworld[pandas])\n",
      "Requirement already satisfied: openpyxl<3.0,>=2.4 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from tabulator<=1.4.1->datadotworld[pandas])\n",
      "Requirement already satisfied: sqlalchemy<2.0,>=1.1 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from tabulator<=1.4.1->datadotworld[pandas])\n",
      "Requirement already satisfied: linear-tsv<2.0,>=1.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from tabulator<=1.4.1->datadotworld[pandas])\n",
      "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from flake8<3.4.1a,>=2.6.0->datadotworld[pandas])\n",
      "Requirement already satisfied: pycodestyle<2.4.0,>=2.0.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from flake8<3.4.1a,>=2.6.0->datadotworld[pandas])\n",
      "Requirement already satisfied: pyflakes<1.6.0,>=1.5.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from flake8<3.4.1a,>=2.6.0->datadotworld[pandas])\n",
      "Requirement already satisfied: pytz>=2011k in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from pandas<1.0a; extra == \"pandas\"->datadotworld[pandas])\n",
      "Requirement already satisfied: numpy>=1.7.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from pandas<1.0a; extra == \"pandas\"->datadotworld[pandas])\n",
      "Requirement already satisfied: jdcal in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from openpyxl<3.0,>=2.4->tabulator<=1.4.1->datadotworld[pandas])\n",
      "Requirement already satisfied: et_xmlfile in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from openpyxl<3.0,>=2.4->tabulator<=1.4.1->datadotworld[pandas])\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<a id='notebook-config'></a>\n",
       "## Notebook Config\n",
       "* python-dotenv\n",
       "* datadotworld"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%env\n",
    "\n",
    "cell_log.clear()\n",
    "cell_log.collect(\"<a id='notebook-config'></a>\")\n",
    "cell_log.collect(\"## Notebook Config\")\n",
    "# ------------ environment variable magic\n",
    "\n",
    "# Install a pip packages in the current Jupyter kernel\n",
    "# ------------ Python-dotenv\n",
    "cell_log.collect(\"* python-dotenv\")\n",
    "import sys\n",
    "!{sys.executable} -m pip install python-dotenv\n",
    "# ------------ data.world API \n",
    "cell_log.collect(\"* datadotworld\")\n",
    "!{sys.executable} -m pip install datadotworld[pandas]\n",
    "\n",
    "Markdown('''{}'''.format(cell_log.getMarkdown()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process\n",
    "## Prepare Data\n",
    "* download github repo with data\n",
    "* put new file in raw-data/\n",
    "* make copy of this jupyter notebook \n",
    "* configure to transform raw-data/ into clean-data/\n",
    "* put clean data into clean/ folder\n",
    "* push final changes to github\n",
    "## Load Data\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='wrangling_steps'></a>\n",
    "# Data Wrangling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='wrangle-process'></a>\n",
    "## Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODE:  prod\n",
      "LOCAL_RAW_FOLDER:  /Users/jameswilfong/Documents/Github/Wilfongjt/source-data/raw-data/\n",
      "LOCAL_CLEAN_FOLDER:  /Users/jameswilfong/Documents/Github/Wilfongjt/source-data/clean-data/\n"
     ]
    }
   ],
   "source": [
    "MODE='prod' # dev, prod\n",
    "LOCAL_RAW_FOLDER = os.getcwd().replace('notebook','raw-data') + '/'\n",
    "LOCAL_CLEAN_FOLDER = os.getcwd().replace('notebook','clean-data') + '/'\n",
    "print('MODE: ', MODE)\n",
    "print('LOCAL_RAW_FOLDER: ', LOCAL_RAW_FOLDER)\n",
    "print('LOCAL_CLEAN_FOLDER: ', LOCAL_CLEAN_FOLDER)\n",
    "# print('GH_URL + table_name: ' + GH_URL + table_name)\n",
    "# print('DW_DB_URL + table_name: ' + DW_DB_URL + table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSourceData(tblDef):\n",
    "    return pd.read_csv(tblDef[\"local_raw\"])\n",
    "\n",
    "def deprecated_getEvaluation(df_source):\n",
    "    #\n",
    "    limit = 0\n",
    "    flds = df_source.columns.tolist()\n",
    "    dups =   {} # {fldname: count of duplicates, ...}\n",
    "    values = {} # {fldname:[list of values], ...}\n",
    "    blanks = {} # {fldname: count of blanks}\n",
    "    minmax = {} # {fldname: {min: value, max: value}\n",
    "    evaluation = {\"duplicates\": dups, \"blanks\": blanks, \"minmax\": minmax}\n",
    "    for fld in flds:\n",
    "        if fld not in dups:\n",
    "            dups[fld] = 0\n",
    "        if fld not in values:\n",
    "            values[fld] = []\n",
    "        if fld not in blanks:\n",
    "            blanks[fld]=0\n",
    "        if fld not in minmax:\n",
    "            minmax[fld]={}\n",
    "            \n",
    "    cnt = 0\n",
    "    # print(flds)\n",
    "    \n",
    "    for row in df_source.values: # loop drains\n",
    "        cnt += 1\n",
    "        # print(row)\n",
    "        for fld in flds:  # loop field names\n",
    "\n",
    "            ifld = flds.index(fld)\n",
    "            if row[ifld] in values[fld]:\n",
    "                dups[fld] += 1\n",
    "            else:\n",
    "                values[fld].append(row[ifld])\n",
    "            \n",
    "            if row[ifld] == ' ' or row[ifld] == None:\n",
    "                blanks[fld] += 1\n",
    "                \n",
    "            if 'min' in minmax[fld]:\n",
    "                if row[ifld] < minmax[fld]['min']:\n",
    "                    minmax[fld]['min'] = row[ifld]\n",
    "            else:\n",
    "                minmax[fld]['min'] = row[ifld]\n",
    "                \n",
    "            if 'max' not in minmax[fld]:  \n",
    "                minmax[fld]['max'] = row[ifld]\n",
    "            \n",
    "            if row[ifld] > minmax[fld]['max']:\n",
    "                minmax[fld]['max'] = row[ifld]\n",
    "            \n",
    "                \n",
    "                \n",
    "        if limit > 0 and limit < cnt:\n",
    "            break\n",
    "            \n",
    "    return evaluation\n",
    "        \n",
    "def getTableDef(table_name, ext='csv'):\n",
    "    return { \"owner_id\": DW_USER, \n",
    "             \"title\": table_name, \n",
    "             \"gh_url\": GH_URL + table_name, \n",
    "             \"visibility\": \"OPEN\", \n",
    "             \"license\": \"Public Domain\",\n",
    "             \"files\": {table_name + '.' + 'csv': {\"url\": GH_URL + table_name + '.' + ext}},\n",
    "             \"dw_url\": DW_DB_URL + table_name + '.' + ext, \n",
    "             \"local_raw\": LOCAL_RAW_FOLDER + table_name + '.' + ext,\n",
    "             \"local_clean\": LOCAL_CLEAN_FOLDER + table_name + '.' + ext\n",
    "           }\n",
    "\n",
    "def loadDataWorld(tbl_def):\n",
    "    '''\n",
    "        Takes a csv file and imports it into dataworld\n",
    "        tbl_def is { \"owner_id\": DW_USER, \n",
    "                     \"title\": table_name, \n",
    "                     \"gh_url\": GH_URL + table_name, \n",
    "                     \"visibility\": \"OPEN\", \n",
    "                     \"license\": \"Public Domain\",\n",
    "                     \"files\": {table_name + '.csv': {\"url\": GH_URL + table_name + '.csv'}},\n",
    "                     \"dw_url\": DW_DB_URL + table_name + '.csv' \n",
    "                    }\n",
    "                    \n",
    "    '''\n",
    "    # api_client.create_dataset(\n",
    "    dw.api_client().create_dataset(    \n",
    "        owner_id=tbl_def[\"owner_id\"], \n",
    "        title=tbl_def[\"title\"], \n",
    "        visibility=tbl_def[\"visibility\"],\n",
    "        license=tbl_def['license'],\n",
    "        files=tbl_def[\"files\"]\n",
    "    )\n",
    "# def renameColumns(df,):    \n",
    "#    df = df.rename(columns=clean_column_names)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "------------- configure source csv\n",
    "'''\n",
    "table_name = 'drains'\n",
    "repo_branch = 'refresh-data'\n",
    "'''\n",
    "------------- configure source csv\n",
    "'''\n",
    "tables = [\n",
    "    getTableDef(table_name)\n",
    "]\n",
    "'''\n",
    "------------- configure outliers\n",
    "'''\n",
    "_outliers = {\n",
    "  'outliers': [\n",
    "    {'column':'dr_facility_id',\n",
    "     'range':(1, 50000000),\n",
    "     'reason':'ignore {} dr_facility_id < 1 or > 50000000.',\n",
    "     'count': 0\n",
    "    }, \n",
    "    {'column':'dr_lon',\n",
    "     'range':(-90.0, -80.0),\n",
    "     'reason':'Remove {} observations too far west or east.',\n",
    "     'count': 0\n",
    "    },  \n",
    "    {'column':'dr_lat',\n",
    "     'range':(40.0, 50.0),\n",
    "     'reason':'Remove {} observations too far north or south.',\n",
    "     'count': 0\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* clean_column_names: 0.005158901214599609 sec\n",
      "       dr_subtype            dr_jurisdiction                      dr_owner  \\\n",
      "27              6           City of Rockford              City of Rockford   \n",
      "144             6            Alpine Township  Kent County Drain Commission   \n",
      "150             6       City of Grand Rapids  Kent County Drain Commission   \n",
      "151             6       City of Grand Rapids  Kent County Drain Commission   \n",
      "152             6       City of Grand Rapids  Kent County Drain Commission   \n",
      "153             6       City of Grand Rapids  Kent County Drain Commission   \n",
      "154             6       City of Grand Rapids  Kent County Drain Commission   \n",
      "155             6       City of Grand Rapids  Kent County Drain Commission   \n",
      "157             6       City of Grand Rapids  Kent County Drain Commission   \n",
      "1870           15  City of East Grand Rapids     City of East Grand Rapids   \n",
      "2570           15  City of East Grand Rapids     City of East Grand Rapids   \n",
      "2571           15  City of East Grand Rapids     City of East Grand Rapids   \n",
      "2648           15  City of East Grand Rapids     City of East Grand Rapids   \n",
      "2651           15  City of East Grand Rapids     City of East Grand Rapids   \n",
      "2653           15  City of East Grand Rapids     City of East Grand Rapids   \n",
      "2654           15  City of East Grand Rapids     City of East Grand Rapids   \n",
      "7997           15       City of Grand Rapids          City of Grand Rapids   \n",
      "8006           15       City of Grand Rapids          City of Grand Rapids   \n",
      "14752          15       City of Grand Rapids          City of Grand Rapids   \n",
      "14828          15         City of Grandville            City of Grandville   \n",
      "15119          15         City of Grandville            City of Grandville   \n",
      "15223          15         City of Grandville            City of Grandville   \n",
      "15268          15         City of Grandville            City of Grandville   \n",
      "16341          15        Georgetown Township           City of Hudsonville   \n",
      "16342          15        Georgetown Township           City of Hudsonville   \n",
      "16343          15        Georgetown Township           City of Hudsonville   \n",
      "16344          15        Georgetown Township           City of Hudsonville   \n",
      "16345          15        Georgetown Township           City of Hudsonville   \n",
      "16346          15        Georgetown Township           City of Hudsonville   \n",
      "16347          15        Georgetown Township           City of Hudsonville   \n",
      "...           ...                        ...                           ...   \n",
      "38405          15             Byron Township   Kent County Road Commission   \n",
      "38406          15             Byron Township   Kent County Road Commission   \n",
      "38407          15             Byron Township   Kent County Road Commission   \n",
      "38409          15             Byron Township   Kent County Road Commission   \n",
      "38410          15             Byron Township   Kent County Road Commission   \n",
      "38411          15             Byron Township   Kent County Road Commission   \n",
      "38412          15             Byron Township   Kent County Road Commission   \n",
      "38413          15             Byron Township   Kent County Road Commission   \n",
      "38414          15             Byron Township   Kent County Road Commission   \n",
      "38661          15            Gaines Township   Kent County Road Commission   \n",
      "38662          15            Gaines Township   Kent County Road Commission   \n",
      "38663          15            Gaines Township   Kent County Road Commission   \n",
      "38664          15            Gaines Township   Kent County Road Commission   \n",
      "38665          15            Gaines Township   Kent County Road Commission   \n",
      "38666          15            Gaines Township   Kent County Road Commission   \n",
      "38667          15            Gaines Township   Kent County Road Commission   \n",
      "38668          15            Gaines Township   Kent County Road Commission   \n",
      "38669          15            Gaines Township   Kent County Road Commission   \n",
      "38670          15            Gaines Township   Kent County Road Commission   \n",
      "38671          15            Gaines Township   Kent County Road Commission   \n",
      "38672          15            Gaines Township   Kent County Road Commission   \n",
      "38673          15            Gaines Township   Kent County Road Commission   \n",
      "38674          15            Gaines Township   Kent County Road Commission   \n",
      "38675          15            Gaines Township   Kent County Road Commission   \n",
      "38676          15            Gaines Township   Kent County Road Commission   \n",
      "38677          15            Gaines Township   Kent County Road Commission   \n",
      "38678          15            Gaines Township   Kent County Road Commission   \n",
      "40654          16            City of Wyoming               City of Wyoming   \n",
      "41798          16            City of Wyoming               City of Wyoming   \n",
      "45171          18       City of Grand Rapids  Kent County Drain Commission   \n",
      "\n",
      "      dr_local_id  dr_facility_id                       dr_subwatershed  \\\n",
      "27         CB3028        40110699                     Lower Rogue River   \n",
      "144                             0                            Mill Creek   \n",
      "150                      40222041                         Plaster Creek   \n",
      "151                      40222041                         Plaster Creek   \n",
      "152                      40222041                         Plaster Creek   \n",
      "153                      40222041                         Plaster Creek   \n",
      "154                      40222041                         Plaster Creek   \n",
      "155                      40222041                         Plaster Creek   \n",
      "157                      40222041                         Plaster Creek   \n",
      "1870     CB4-1658               0                         Plaster Creek   \n",
      "2570      CB1-203        40229552  Direct Drainage to Lower Grand River   \n",
      "2571      CB1-202        40229552  Direct Drainage to Lower Grand River   \n",
      "2648      CB1-246        40230649  Direct Drainage to Lower Grand River   \n",
      "2651     CB1-2028        40231011  Direct Drainage to Lower Grand River   \n",
      "2653      CB1-228        40231073  Direct Drainage to Lower Grand River   \n",
      "2654      CB1-229        40231073  Direct Drainage to Lower Grand River   \n",
      "7997                     40215206                         Plaster Creek   \n",
      "8006                     40215206                         Plaster Creek   \n",
      "14752                    40223488  Direct Drainage to Lower Grand River   \n",
      "14828                    40159311                            Buck Creek   \n",
      "15119                    40159299  Direct Drainage to Lower Grand River   \n",
      "15223                    40159311                            Buck Creek   \n",
      "15268                    40159299  Direct Drainage to Lower Grand River   \n",
      "16341                    40247437                            Rush Creek   \n",
      "16342                    40247437                            Rush Creek   \n",
      "16343                    40247437                            Rush Creek   \n",
      "16344                    40247437                            Rush Creek   \n",
      "16345                    40247437                            Rush Creek   \n",
      "16346                    40247437                            Rush Creek   \n",
      "16347                    40247437                            Rush Creek   \n",
      "...           ...             ...                                   ...   \n",
      "38405                    40261706                            Buck Creek   \n",
      "38406                    40261706                            Buck Creek   \n",
      "38407                    40261817                            Buck Creek   \n",
      "38409                    40261817                            Buck Creek   \n",
      "38410                    40261817                            Buck Creek   \n",
      "38411                    40261817                            Buck Creek   \n",
      "38412                    40261817                            Buck Creek   \n",
      "38413                    40261817                            Buck Creek   \n",
      "38414                    40261817                            Buck Creek   \n",
      "38661                    40265737                         Plaster Creek   \n",
      "38662                    40265736                         Plaster Creek   \n",
      "38663                    40265736                         Plaster Creek   \n",
      "38664                    40265736                         Plaster Creek   \n",
      "38665                    40265737                         Plaster Creek   \n",
      "38666                    40265737                         Plaster Creek   \n",
      "38667                    40265737                         Plaster Creek   \n",
      "38668                    40265737                         Plaster Creek   \n",
      "38669                    40265737                         Plaster Creek   \n",
      "38670                    40265737                         Plaster Creek   \n",
      "38671                    40265737                         Plaster Creek   \n",
      "38672                    40265737                         Plaster Creek   \n",
      "38673                    40265737                         Plaster Creek   \n",
      "38674                    40265737                         Plaster Creek   \n",
      "38675                    40265737                         Plaster Creek   \n",
      "38676                    40265737                         Plaster Creek   \n",
      "38677                    40265737                         Plaster Creek   \n",
      "38678                    40265737                         Plaster Creek   \n",
      "40654        3729        40115860  Direct Drainage to Lower Grand River   \n",
      "41798        3729        40115860  Direct Drainage to Lower Grand River   \n",
      "45171                    40222041                         Plaster Creek   \n",
      "\n",
      "          dr_lon     dr_lat  \n",
      "27    -85.558243  43.123959  \n",
      "144   -85.696324  43.069081  \n",
      "150   -85.597028  42.919356  \n",
      "151   -85.597800  42.919359  \n",
      "152   -85.598142  42.919363  \n",
      "153   -85.596602  42.919217  \n",
      "154   -85.597468  42.919351  \n",
      "155   -85.596581  42.919093  \n",
      "157   -85.596764  42.919348  \n",
      "1870  -85.614364  42.942881  \n",
      "2570  -85.614084  42.953295  \n",
      "2571  -85.614243  42.953273  \n",
      "2648  -85.613718  42.950147  \n",
      "2651  -85.615773  42.950210  \n",
      "2653  -85.615426  42.951134  \n",
      "2654  -85.615398  42.951000  \n",
      "7997  -85.608027  42.909229  \n",
      "8006  -85.608064  42.909761  \n",
      "14752 -85.746842  42.978896  \n",
      "14828 -85.773260  42.908882  \n",
      "15119 -85.772047  42.908930  \n",
      "15223 -85.773260  42.908882  \n",
      "15268 -85.772047  42.908930  \n",
      "16341 -85.889826  42.862196  \n",
      "16342 -85.889829  42.862258  \n",
      "16343 -85.888747  42.862224  \n",
      "16344 -85.888751  42.862287  \n",
      "16345 -85.889295  42.862612  \n",
      "16346 -85.889448  42.863031  \n",
      "16347 -85.889445  42.863106  \n",
      "...          ...        ...  \n",
      "38405 -85.701683  42.821947  \n",
      "38406 -85.701546  42.821957  \n",
      "38407 -85.698720  42.821277  \n",
      "38409 -85.700525  42.822391  \n",
      "38410 -85.700517  42.822318  \n",
      "38411 -85.699401  42.822396  \n",
      "38412 -85.699397  42.822314  \n",
      "38413 -85.698254  42.821953  \n",
      "38414 -85.698362  42.821930  \n",
      "38661 -85.590739  42.842256  \n",
      "38662 -85.590642  42.842258  \n",
      "38663 -85.590745  42.841520  \n",
      "38664 -85.590622  42.841523  \n",
      "38665 -85.590676  42.843231  \n",
      "38666 -85.590799  42.843196  \n",
      "38667 -85.590192  42.843814  \n",
      "38668 -85.590192  42.843742  \n",
      "38669 -85.590716  42.844084  \n",
      "38670 -85.590831  42.844106  \n",
      "38671 -85.591259  42.844564  \n",
      "38672 -85.591205  42.844633  \n",
      "38673 -85.591986  42.843812  \n",
      "38674 -85.592091  42.843742  \n",
      "38675 -85.591983  42.842813  \n",
      "38676 -85.591851  42.842910  \n",
      "38677 -85.592624  42.843797  \n",
      "38678 -85.592628  42.843883  \n",
      "40654 -85.727699  42.909379  \n",
      "41798 -85.727699  42.909379  \n",
      "45171 -85.598514  42.919377  \n",
      "\n",
      "[496 rows x 8 columns]\n",
      "* remove_obvious_outliers: 0.010251998901367188 sec\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# CSV Process\n",
       "* input:  /Users/jameswilfong/Documents/Github/Wilfongjt/source-data/raw-data/drains.csv\n",
       "* clean: Apply a style of lowercase and underscores to column names.\n",
       "* clean: mark bad dr_facility_id values ('',' ',None,NaN') with 0\n",
       "* clean: convert dr_facility_id column to int64\n",
       "* clean: mark all duplicate facility_ids with 0\n",
       "* outlier: ignore 17 dr_facility_id < 1 or > 50000000.\n",
       "* outlier: Remove 0 observations too far west or east.\n",
       "* outlier: Remove 0 observations too far north or south.\n",
       "* remove: /Users/jameswilfong/Documents/Github/Wilfongjt/source-data/clean-data/drains.csv\n",
       "* output: /Users/jameswilfong/Documents/Github/Wilfongjt/source-data/clean-data/drains.csv\n",
       "\n",
       "# GIT Process\n",
       "* input: /Users/jameswilfong/Documents/Github/Wilfongjt/source-data/clean-data/drains.csv\n",
       "* git add raw-data/ -A\n",
       "* git add clean-data/ -A\n",
       "* git add notebook/ -A\n",
       "* git add ../README.md -A\n",
       "* git commit -m \"update raw-data, clean-data, and notebook files \"\n",
       "* git push origin refresh-data\n",
       "\n",
       "# Data.World Process\n",
       "* input: https://raw.githubusercontent.com/Wilfongjt/source-data/refresh-data/clean-data/drains.csv\n",
       "* load data into data.world\n",
       "* output: https://api.data.world/v0/datasets/wilfongjt/drains.csv"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_log.clear()\n",
    "\n",
    "\n",
    "cell_log.collect(\"# CSV Process\")\n",
    "'''\n",
    "--------------------------------- input\n",
    "'''\n",
    "for tbl in tables:\n",
    "    cell_log.collect(\"* input:  {}\".format( tbl[\"local_raw\"]))\n",
    "\n",
    "'''\n",
    "--------------------------------- load data\n",
    "''' \n",
    "tbl = tables[0]\n",
    "# df_source = pd.read_csv(tbl[\"local_raw\"])\n",
    "\n",
    "df_source = getSourceData(tbl)\n",
    "'''\n",
    "--------------------------------- check for duplicates\n",
    "''' \n",
    "#  dups = getEvaluation(df_source)\n",
    "#  print(dups)\n",
    "\n",
    "'''\n",
    "--------------------------------- clean column names\n",
    "'''\n",
    "cell_log.collect('* clean: Apply a style of lowercase and underscores to column names.')##############################\n",
    "df_source = clean.clean_column_names(df_source)\n",
    "\n",
    "'''\n",
    "--------------------------------- rename columns\n",
    "'''\n",
    "# df_source['lon'] = df_source['trk_crnt_x_cord']\n",
    "# df_source['lat'] = df_source['trk_crnt_y_cord']\n",
    "df_source = df_source.rename(columns={\n",
    "    \"subtype\": \"dr_subtype\",\n",
    "    \"drain__owner\": \"dr_owner\",\n",
    "    \"local__id\": \"dr_local_id\",\n",
    "    \"facilityid\": \"dr_facility_id\",\n",
    "    \"drain__jurisdiction\": \"dr_jurisdiction\",\n",
    "    \"subwatershed\": \"dr_subwatershed\",\n",
    "    \"point__x\":\"dr_lon\", \n",
    "    \"point__y\":\"dr_lat\"})\n",
    "\n",
    "# print('info: ',df_source.info())\n",
    "'''\n",
    "--------------------------------- change value\n",
    "'''\n",
    "# change '', ' ', None, and NaN to -1\n",
    "def_facility_id = _outliers['outliers'][0]['range'][0] - 1\n",
    "cell_log.collect(\"* clean: mark bad dr_facility_id values ('',' ',None,NaN') with {}\".format(def_facility_id))\n",
    "df_source['dr_facility_id'] = df_source['dr_facility_id'].apply(lambda x:  def_facility_id if x != x or x == '' or x == ' ' or x == None else x)\n",
    "\n",
    "'''\n",
    "--------------------------------- change column types\n",
    "'''\n",
    "cell_log.collect('* clean: convert dr_facility_id column to int64')\n",
    "df_source['dr_facility_id'] = df_source['dr_facility_id'].astype('int64')\n",
    "'''\n",
    "--------------------------------- duplicates\n",
    "'''\n",
    "cell_log.collect('* clean: mark all duplicate facility_ids with {}'.format(def_facility_id))\n",
    "# df_bigdata_duplicates = df_source[df_source.duplicated(cols='dr_facility_id',take_last=False)|df_source.duplicated(cols='dr_facility_id',take_last=True)]\n",
    "# df_bigdata_duplicates = df_source.duplicated(['dr_facility_id'], keep=False)\n",
    "df_bigdata_duplicates = df_source[df_source.duplicated(['dr_facility_id'], keep=False)]\n",
    "\n",
    "print(df_bigdata_duplicates)\n",
    "\n",
    "'''\n",
    "--------------------------------- outliers\n",
    "'''\n",
    "df_source = clean.remove_obvious_outliers(_outliers, df_source)\n",
    "# cell_log.collect('# Outliers')\n",
    "for r in _outliers['outliers']:##############################\n",
    "    cell_log.collect('* outlier: {}'.format(r['reason']))\n",
    "\n",
    "'''\n",
    "--------------------------------- save csv \n",
    "'''\n",
    "# cell_log.collect('# Output')\n",
    "# assume new file and remove old one\n",
    "if os.path.isfile(tbl[\"local_clean\"]):\n",
    "    os.remove(tbl['local_clean'])\n",
    "    cell_log.collect('* remove: ' + tbl['local_clean'])\n",
    "cell_log.collect('* output: ' + tbl[\"local_clean\"])\n",
    "df_source.to_csv(tbl[\"local_clean\"], index=False)\n",
    "\n",
    "\n",
    "if MODE == 'dev':\n",
    "    print('info: ',df_source.info())\n",
    "    print('head: ',df_source.head())  \n",
    "    \n",
    "if MODE == 'prod':    \n",
    "    '''\n",
    "    run extra git commands\n",
    "    run import to data.word\n",
    "    '''\n",
    "    '''\n",
    "    --------------------------------- GIT Process \n",
    "    '''\n",
    "    cell_log.collect('')\n",
    "    cell_log.collect('# GIT Process')\n",
    "    '''\n",
    "    --------------------------------- input\n",
    "    '''\n",
    "    cell_log.collect('* input: ' + tbl[\"local_clean\"])\n",
    "    '''\n",
    "    --------------------------------- git add\n",
    "    '''\n",
    " \n",
    "    cell_log.collect('* git add raw-data/ -A')\n",
    "    output = subprocess.check_output([\"git\", \"add\", \"../raw-data\" ,\"-A\"])\n",
    "    cell_log.collect('* git add clean-data/ -A' )\n",
    "    output = subprocess.check_output([\"git\", \"add\", \"../clean-data\" ,\"-A\"])\n",
    "    cell_log.collect('* git add notebook/ -A' )\n",
    "    output = subprocess.check_output([\"git\", \"add\", \"../notebook\"])\n",
    "    cell_log.collect('* git add ../README.md -A' )\n",
    "    output = subprocess.check_output([\"git\", \"add\", \"../README.md\"])\n",
    "    '''\n",
    "    --------------------------------- git commit\n",
    "    '''\n",
    "    # cell_log.collect('* XXXXXXX git commit -m \"update raw-data {}\"'.format(tbl[\"local_raw\"]) )\n",
    "    # cell_log.collect('* XXXXXXX git commit -m \"update clean-data {}\"'.format(\"local_clean\") )\n",
    "    cell_log.collect('* git commit -m \"update raw-data, clean-data, and notebook files \"' )\n",
    "\n",
    "    # output = subprocess.check_output([\"git\", \"commit\", \"-m\", \"'update raw-data, clean-data, and notebook files'\"])\n",
    "\n",
    "\n",
    "    try:\n",
    "        output = subprocess.check_output([\"git\", \"commit\", \"-m\", \"'update raw-data, clean-data, and notebook files'\"])\n",
    "    except subprocess.CalledProcessError as error:\n",
    "        print(error)\n",
    "    except:\n",
    "        cell_log.collect('* unknown error' )\n",
    "    '''\n",
    "    --------------------------------- git push\n",
    "    '''\n",
    "    cell_log.collect('* git push origin ' + repo_branch)\n",
    "    output = subprocess.check_output([\"git\", \"push\", \"origin\", repo_branch])\n",
    "\n",
    "    '''\n",
    "    --------------------------------- Data World Process \n",
    "    '''\n",
    "    \n",
    "    cell_log.collect('')\n",
    "    cell_log.collect('# Data.World Process')\n",
    "    cell_log.collect('* input: {}'.format(tbl[\"gh_url\"] + \".csv\") )\n",
    "    cell_log.collect('* load data into data.world')\n",
    "    # loadDataWorld(tbl)\n",
    "    cell_log.collect('* output: {}'.format(tbl[\"dw_url\"] ))\n",
    "    \n",
    "Markdown('''{}'''.format(cell_log.getMarkdown()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
