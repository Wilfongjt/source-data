{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lib.p3_ProcessLogger import ProcessLogger\n",
    "cell_log = ProcessLogger() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Project: Adopt a Drain\n",
    " * Author: James Wilfong, wilfongjt@gmail.com\n",
    " \n",
    "## Basics\n",
    "* data processed in a local clone of source-data \n",
    "* intermediate files are put into source-data repo\n",
    "* the final data.world data set name is the same as the raw-data file name\n",
    "* the source-data repo folders /raw-data, /clean-data, /notebook are updated during the process\n",
    "\n",
    "## Raw-data Process\n",
    "* input: raw-data/ \n",
    "* use python via jupyter notebook to manipulate data into usable file\n",
    "* update results to github\n",
    "* output: clean-data/\n",
    "\n",
    "## GIT Process\n",
    "* input: clean-data/\n",
    "* process: add, commit, push files from raw-data/, clean-data/, notebook/ folders\n",
    "* output: GitHub source-data repo\n",
    "\n",
    "## Data.World Process\n",
    "* input: GitHub source-data/clean-data/\n",
    "* process: transfer github clean-data/ to data.world\n",
    "* output: data.world\n",
    "\n",
    "## Table of Contents\n",
    "* [Introduction](#intro)\n",
    "\n",
    "* [Data Wrangling](#wrangling_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## Introduction\n",
    "* why adopt a drain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prerequisites'></a>\n",
    "## Prerequisites\n",
    "* create [Github](#github) repository to hold raw data\n",
    "* create [Data World](#data-world) account\n",
    "* [Notebook Config](#notebook-config)\n",
    "* [Environment Variable Setup](#env-setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data-world'></a>\n",
    "## Dataworld\n",
    "* Set up an account\n",
    "* DW_AUTH_TOKEN value comes from your [data.world](https://data.world/) account-settings-advanced-Admin.\n",
    "* Application data is stored in data.world\n",
    "* A Data.world dataset is mostly read-only\n",
    "* A Data.world is updated via file replacement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='github'></a>\n",
    "## Github\n",
    "\n",
    "* raw-data is loaded from the remote source-data repo on Github\n",
    "* raw-data is stored in the /raw-data folder of the source-data repo\n",
    "* raw-data is pushed to the remote source-data repo before running this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='env-setup'></a>\n",
    "## Environment Variable Setup\n",
    "* Create a file .env and put in the /notebook folder\n",
    "* .env does not get included in the github repository. Exclude .env from github in the .gitignore file\n",
    "* Add environment variables to .env file\n",
    "    * DW_USER=your-data-world-user-name\n",
    "    * GH_URL=https://raw.githubusercontent.com/Wilfongjt/source-data/master/raw-data/\n",
    "    * DW_DB_URL=https://api.data.world/v0/datasets/wilfongjt/\n",
    "    * DW_DB_RW_TOKEN=dataworld-token\n",
    "    * DW_ADM_TOKEN=dataworld-adm-token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Load Packages\n",
       "* Load environment variables\n",
       "* Import third party packages\n",
       "* Import custom packages"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_log.clear()\n",
    "cell_log.collect('## Load Packages')\n",
    "# import dotenv\n",
    "cell_log.collect('* Load environment variables')\n",
    "from settings import *\n",
    "cell_log.collect('* Import third party packages')\n",
    "# from exceptions import ApiException\n",
    "from datadotworld.client import _swagger\n",
    "import datadotworld as dw\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import csv # read and write csv files\n",
    "from IPython.display import display, HTML\n",
    "from IPython.display import Markdown\n",
    "from pprint import pprint\n",
    "import time\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# convenience functions -- cleaning\n",
    "cell_log.collect('* Import custom packages')\n",
    "from lib.p3_CellCounts import CellCounts\n",
    "import lib.p3_clean as clean\n",
    "from lib.p3_configuration import get_configuration\n",
    "import lib.p3_explore as explore\n",
    "import lib.p3_gather as gather # gathering functions\n",
    "import lib.p3_helper_functions as helper\n",
    "import lib.p3_map as maps\n",
    "\n",
    "Markdown('''{}'''.format(cell_log.getMarkdown()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /Users/jameswilfong/anaconda/lib/python3.6/site-packages\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: datadotworld[pandas] in /Users/jameswilfong/anaconda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: certifi>=2017.04.17 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from datadotworld[pandas])\n",
      "Requirement already satisfied: six<2.0a,>=1.5.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from datadotworld[pandas])\n",
      "Requirement already satisfied: urllib3<2.0a,>=1.15 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from datadotworld[pandas])\n",
      "Requirement already satisfied: jsontableschema<1.0a,>=0.10.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from datadotworld[pandas])\n",
      "Requirement already satisfied: tabulator<=1.4.1 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from datadotworld[pandas])\n",
      "Requirement already satisfied: python-dateutil<3.0a,>=2.6.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from datadotworld[pandas])\n",
      "Requirement already satisfied: requests<3.0a,>=2.0.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from datadotworld[pandas])\n",
      "Requirement already satisfied: click<7.0a,>=6.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from datadotworld[pandas])\n",
      "Requirement already satisfied: flake8<3.4.1a,>=2.6.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from datadotworld[pandas])\n",
      "Requirement already satisfied: configparser<4.0a,>=3.5.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from datadotworld[pandas])\n",
      "Requirement already satisfied: datapackage<1.0a,>=0.8.8 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from datadotworld[pandas])\n",
      "Requirement already satisfied: pandas<1.0a; extra == \"pandas\" in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from datadotworld[pandas])\n",
      "Requirement already satisfied: jsonschema<3.0,>=2.5 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from jsontableschema<1.0a,>=0.10.0->datadotworld[pandas])\n",
      "Requirement already satisfied: future<1.0,>=0.15 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from jsontableschema<1.0a,>=0.10.0->datadotworld[pandas])\n",
      "Requirement already satisfied: rfc3986<1.0,>=0.4 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from jsontableschema<1.0a,>=0.10.0->datadotworld[pandas])\n",
      "Requirement already satisfied: isodate<1.0,>=0.5.4 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from jsontableschema<1.0a,>=0.10.0->datadotworld[pandas])\n",
      "Requirement already satisfied: unicodecsv<1.0,>=0.14 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from jsontableschema<1.0a,>=0.10.0->datadotworld[pandas])\n",
      "Requirement already satisfied: linear-tsv<2.0,>=1.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from tabulator<=1.4.1->datadotworld[pandas])\n",
      "Requirement already satisfied: sqlalchemy<2.0,>=1.1 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from tabulator<=1.4.1->datadotworld[pandas])\n",
      "Requirement already satisfied: ijson<3.0,>=2.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from tabulator<=1.4.1->datadotworld[pandas])\n",
      "Requirement already satisfied: openpyxl<3.0,>=2.4 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from tabulator<=1.4.1->datadotworld[pandas])\n",
      "Requirement already satisfied: jsonlines<2.0,>=1.1 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from tabulator<=1.4.1->datadotworld[pandas])\n",
      "Requirement already satisfied: xlrd<2.0,>=1.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from tabulator<=1.4.1->datadotworld[pandas])\n",
      "Requirement already satisfied: cchardet<2.0,>=1.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from tabulator<=1.4.1->datadotworld[pandas])\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from requests<3.0a,>=2.0.0->datadotworld[pandas])\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from requests<3.0a,>=2.0.0->datadotworld[pandas])\n",
      "Requirement already satisfied: pyflakes<1.6.0,>=1.5.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from flake8<3.4.1a,>=2.6.0->datadotworld[pandas])\n",
      "Requirement already satisfied: pycodestyle<2.4.0,>=2.0.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from flake8<3.4.1a,>=2.6.0->datadotworld[pandas])\n",
      "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from flake8<3.4.1a,>=2.6.0->datadotworld[pandas])\n",
      "Requirement already satisfied: pytz>=2011k in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from pandas<1.0a; extra == \"pandas\"->datadotworld[pandas])\n",
      "Requirement already satisfied: numpy>=1.7.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from pandas<1.0a; extra == \"pandas\"->datadotworld[pandas])\n",
      "Requirement already satisfied: jdcal in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from openpyxl<3.0,>=2.4->tabulator<=1.4.1->datadotworld[pandas])\n",
      "Requirement already satisfied: et_xmlfile in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from openpyxl<3.0,>=2.4->tabulator<=1.4.1->datadotworld[pandas])\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<a id='notebook-config'></a>\n",
       "## Notebook Config\n",
       "* python-dotenv\n",
       "* datadotworld"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%env\n",
    "\n",
    "cell_log.clear()\n",
    "cell_log.collect(\"<a id='notebook-config'></a>\")\n",
    "cell_log.collect(\"## Notebook Config\")\n",
    "# ------------ environment variable magic\n",
    "\n",
    "# Install a pip packages in the current Jupyter kernel\n",
    "# ------------ Python-dotenv\n",
    "cell_log.collect(\"* python-dotenv\")\n",
    "import sys\n",
    "!{sys.executable} -m pip install python-dotenv\n",
    "# ------------ data.world API \n",
    "cell_log.collect(\"* datadotworld\")\n",
    "!{sys.executable} -m pip install datadotworld[pandas]\n",
    "\n",
    "Markdown('''{}'''.format(cell_log.getMarkdown()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process\n",
    "## Prepare Data\n",
    "* download github repo with data\n",
    "* put new file in raw-data/\n",
    "* make copy of this jupyter notebook \n",
    "* configure to transform raw-data/ into clean-data/\n",
    "* put clean data into clean/ folder\n",
    "* push final changes to github\n",
    "## Load Data\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='wrangling_steps'></a>\n",
    "# Data Wrangling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='wrangle-process'></a>\n",
    "## Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODE:  prod\n",
      "LOCAL_RAW_FOLDER:  /Users/jameswilfong/Documents/Github/Wilfongjt/source-data/raw-data/\n",
      "LOCAL_CLEAN_FOLDER:  /Users/jameswilfong/Documents/Github/Wilfongjt/source-data/clean-data/\n"
     ]
    }
   ],
   "source": [
    "MODE='prod' # dev, prod\n",
    "LOCAL_RAW_FOLDER = os.getcwd().replace('notebook','raw-data') + '/'\n",
    "LOCAL_CLEAN_FOLDER = os.getcwd().replace('notebook','clean-data') + '/'\n",
    "print('MODE: ', MODE)\n",
    "print('LOCAL_RAW_FOLDER: ', LOCAL_RAW_FOLDER)\n",
    "print('LOCAL_CLEAN_FOLDER: ', LOCAL_CLEAN_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTableDef(table_name, ext='csv'):\n",
    "    return { \"owner_id\": DW_USER, \n",
    "             \"title\": table_name, \n",
    "             \"gh_url\": GH_URL + table_name, \n",
    "             \"visibility\": \"OPEN\", \n",
    "             \"license\": \"Public Domain\",\n",
    "             \"files\": {table_name + '.' + 'csv': {\"url\": GH_URL + table_name + '.' + ext}},\n",
    "             \"dw_url\": DW_DB_URL + table_name + '.' + ext, \n",
    "             \"local_raw\": LOCAL_RAW_FOLDER + table_name + '.' + ext,\n",
    "             \"local_clean\": LOCAL_CLEAN_FOLDER + table_name + '.' + ext\n",
    "           }\n",
    "\n",
    "def loadDataWorld(tbl_def):\n",
    "    '''\n",
    "        Takes a csv file and imports it into dataworld\n",
    "        tbl_def is { \"owner_id\": DW_USER, \n",
    "                     \"title\": table_name, \n",
    "                     \"gh_url\": GH_URL + table_name, \n",
    "                     \"visibility\": \"OPEN\", \n",
    "                     \"license\": \"Public Domain\",\n",
    "                     \"files\": {table_name + '.csv': {\"url\": GH_URL + table_name + '.csv'}},\n",
    "                     \"dw_url\": DW_DB_URL + table_name + '.csv' \n",
    "                    }\n",
    "    '''\n",
    "    api_client.create_dataset(\n",
    "        owner_id=d_dic[\"owner_id\"], \n",
    "        title=d_dic[\"title\"], \n",
    "        visibility=d_dic[\"visibility\"],\n",
    "        license=d_dic['license'],\n",
    "        files=d_dic[\"files\"]\n",
    "    )\n",
    "# def renameColumns(df,):    \n",
    "#    df = df.rename(columns=clean_column_names)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "------------- configure source csv\n",
    "'''\n",
    "table_name = 'catch_basins'\n",
    "repo_branch = 'refresh-data'\n",
    "'''\n",
    "------------- configure source csv\n",
    "'''\n",
    "tables = [\n",
    "    getTableDef(table_name)\n",
    "]\n",
    "'''\n",
    "------------- configure outliers\n",
    "'''\n",
    "_outliers = {\n",
    "  'outliers': [\n",
    "    {'column':'dr_lon',\n",
    "     'range':(-90.0, -80.0),\n",
    "     'reason':'Remove observations too far west or east.'},  \n",
    "    {'column':'dr_lat',\n",
    "     'range':(40.0, 50.0),\n",
    "     'reason':'Remove observations too far north or south.'}\n",
    "      \n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* clean_column_names: 0.005074024200439453 sec\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45841 entries, 0 to 45840\n",
      "Data columns (total 8 columns):\n",
      "dr_subtype         45841 non-null int64\n",
      "dr_jurisdiction    45841 non-null object\n",
      "dr_owner           45841 non-null object\n",
      "dr_local_id        45841 non-null object\n",
      "dr_facility_id     45841 non-null object\n",
      "dr_subwatershed    45841 non-null object\n",
      "dr_lon             45841 non-null float64\n",
      "dr_lat             45841 non-null float64\n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 2.8+ MB\n",
      "info:  None\n",
      "* remove_obvious_outliers: 0.007478952407836914 sec\n",
      "Command '['git', 'commit', '-m', \"'update raw-data, clean-data, and notebook files'\"]' returned non-zero exit status 1.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'api_client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-c7b4f30d3c2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    114\u001b[0m     '''\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mloadDataWorld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtbl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mcell_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-184f27dae90e>\u001b[0m in \u001b[0;36mloadDataWorld\u001b[0;34m(tbl_def)\u001b[0m\n\u001b[1;32m     23\u001b[0m                     }\n\u001b[1;32m     24\u001b[0m     '''\n\u001b[0;32m---> 25\u001b[0;31m     api_client.create_dataset(\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mowner_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"owner_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"title\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'api_client' is not defined"
     ]
    }
   ],
   "source": [
    "cell_log.clear()\n",
    "\n",
    "\n",
    "cell_log.collect(\"# CSV Process\")\n",
    "'''\n",
    "--------------------------------- input\n",
    "'''\n",
    "for tbl in tables:\n",
    "    cell_log.collect(\"* input:  {}\".format( tbl[\"local_raw\"]))\n",
    "\n",
    "'''\n",
    "--------------------------------- load data\n",
    "''' \n",
    "tbl = tables[0]\n",
    "df_source = pd.read_csv(tbl[\"local_raw\"])\n",
    "\n",
    "'''\n",
    "--------------------------------- clean column names\n",
    "'''\n",
    "cell_log.collect('* clean: Apply a style of lowercase and underscores to column names.')##############################\n",
    "df_source = clean.clean_column_names(df_source)\n",
    "\n",
    "'''\n",
    "--------------------------------- rename columns\n",
    "'''\n",
    "# df_source['lon'] = df_source['trk_crnt_x_cord']\n",
    "# df_source['lat'] = df_source['trk_crnt_y_cord']\n",
    "df_source = df_source.rename(columns={\n",
    "    \"subtype\": \"dr_subtype\",\n",
    "    \"drain__owner\": \"dr_owner\",\n",
    "    \"local__id\": \"dr_local_id\",\n",
    "    \"facilityid\": \"dr_facility_id\",\n",
    "    \"drain__jurisdiction\": \"dr_jurisdiction\",\n",
    "    \"subwatershed\": \"dr_subwatershed\",\n",
    "    \"point__x\":\"dr_lon\", \n",
    "    \"point__y\":\"dr_lat\"})\n",
    "\n",
    "print('info: ',df_source.info())\n",
    "\n",
    "'''\n",
    "--------------------------------- outliers\n",
    "'''\n",
    "df_source = clean.remove_obvious_outliers(_outliers, df_source)\n",
    "# cell_log.collect('# Outliers')\n",
    "for r in _outliers['outliers']:##############################\n",
    "    cell_log.collect('* outlier: {}'.format(r['reason']))\n",
    "\n",
    "'''\n",
    "--------------------------------- save csv \n",
    "'''\n",
    "# cell_log.collect('# Output')\n",
    "# assume new file and remove old one\n",
    "if os.path.isfile(tbl[\"local_clean\"]):\n",
    "    os.remove(tbl['local_clean'])\n",
    "    cell_log.collect('* remove: ' + tbl['local_clean'])\n",
    "cell_log.collect('* output: ' + tbl[\"local_clean\"])\n",
    "df_source.to_csv(tbl[\"local_clean\"], index=False)\n",
    "\n",
    "\n",
    "if MODE == 'dev':\n",
    "    print('info: ',df_source.info())\n",
    "    print('head: ',df_source.head())  \n",
    "    \n",
    "if MODE == 'prod':    \n",
    "    '''\n",
    "    run extra git commands\n",
    "    run import to data.word\n",
    "    '''\n",
    "    '''\n",
    "    --------------------------------- GIT Process \n",
    "    '''\n",
    "    cell_log.collect('')\n",
    "    cell_log.collect('# GIT Process')\n",
    "    '''\n",
    "    --------------------------------- input\n",
    "    '''\n",
    "    cell_log.collect('* input: ' + tbl[\"local_clean\"])\n",
    "    '''\n",
    "    --------------------------------- git add\n",
    "    '''\n",
    " \n",
    "    cell_log.collect('* git add raw-data/ -A')\n",
    "    output = subprocess.check_output([\"git\", \"add\", \"../raw-data\" ,\"-A\"])\n",
    "    cell_log.collect('* git add clean-data/ -A' )\n",
    "    output = subprocess.check_output([\"git\", \"add\", \"../clean-data\" ,\"-A\"])\n",
    "    cell_log.collect('* git add notebook/ -A' )\n",
    "    output = subprocess.check_output([\"git\", \"add\", \"../notebook\"])\n",
    "    cell_log.collect('* git add ../README.md -A' )\n",
    "    output = subprocess.check_output([\"git\", \"add\", \"../README.md\"])\n",
    "    '''\n",
    "    --------------------------------- git commit\n",
    "    '''\n",
    "    # cell_log.collect('* XXXXXXX git commit -m \"update raw-data {}\"'.format(tbl[\"local_raw\"]) )\n",
    "    # cell_log.collect('* XXXXXXX git commit -m \"update clean-data {}\"'.format(\"local_clean\") )\n",
    "    cell_log.collect('* git commit -m \"update raw-data, clean-data, and notebook files \"' )\n",
    "\n",
    "    # output = subprocess.check_output([\"git\", \"commit\", \"-m\", \"'update raw-data, clean-data, and notebook files'\"])\n",
    "\n",
    "\n",
    "    try:\n",
    "        output = subprocess.check_output([\"git\", \"commit\", \"-m\", \"'update raw-data, clean-data, and notebook files'\"])\n",
    "    except subprocess.CalledProcessError as error:\n",
    "        print(error)\n",
    "    except:\n",
    "        cell_log.collect('* unknown error' )\n",
    "    '''\n",
    "    --------------------------------- git push\n",
    "    '''\n",
    "    cell_log.collect('* git push origin ' + repo_branch)\n",
    "    output = subprocess.check_output([\"git\", \"push\", \"origin\", repo_branch])\n",
    "\n",
    "    '''\n",
    "    --------------------------------- Data World Process \n",
    "    '''\n",
    "    \n",
    "    loadDataWorld(tbl)\n",
    "    \n",
    "    cell_log.collect('')\n",
    "    cell_log.collect('# Data.World Process')\n",
    "\n",
    "    \n",
    "Markdown('''{}'''.format(cell_log.getMarkdown()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
